Yal2JVM Compiler
Group 31

-- Names, Numbers, Grades, Contributions --

Ana Margarida Oliveira Pinheiro da Silva, up201505505, 16, 25%
Luís Miguel Cardoso Lopes Correia, up201503342, 16, 25%
Pedro Daniel dos Santos Reis, up201506046, 16, 25%
Vicente Fernandes Ramada Caldeira Espinha, up201503764, 16, 25%

-- SUMMARY --

Our project is a compiler, capable of parsing Yal code, evaluate its syntax,
interpret its semantics and generate the respective code. 

-- EXECUTE -- 

In order to run our code, we have included a little script to help build the program.
To build, run the command in the terminal:

./script.sh

After that, if no problems were detected, the project has finished building, and is now ready
to compile a file. The command must be written in the following form:

java yal2jvm <FileName>

-- DEALING WITH SYNTACTIC ERRORS -- 

To detect semantic errors, the compiler goes through every single word in the file,
and matches to see if it is one of the accepted terminals. If it is, it consumes that word, 
and continues the parsing. If it is not, the program prints out an error message regarding
what type of error it was, as well as information about what type of terminals it was expecting.

The program then skips to the next predetermined terminal, usually a ';' or '}'. That way it can 
continue to analyse the rest of the file without stopping at the first exception found.  It does 
not stop looking through the file until the the ending character of the file is reached (<EOF>).

-- SEMANTIC ANALYSIS --

The semantic analysis is done through analysis of the AST generated by the parser. Every leaf
of the AST has its own type, value, and initialization, stored in the SimpleNode. In order to 
maintain information from previous parts of the tree, it stores three structures: one ArrayList
for declarations, another one for functions, and an HashMap for the Symbol Tree. This is composed
by an ArrayList of SimpleNodes, with a String as key, that being the function name. This is critical
to check the scope of variables. This allows the program to identify which variables are of which function,
and maintain information about its initialization.

It is designed in a way to identify semantic errors and warnings, such as incorrect initializations,
incorrect uses of numbers or operators, and type comparison between variables (scalars and arrays).
If an error is found, it is printed out to the console, with some information about the variable(s) 
responsible for the triggering of said error. 

It can also analyse calls, both of the same module, as well as of external packages. It analyses
the expected return type, and matches the length and type of variables passed as arguments to see
if the call is being performed correctly.

Another key component of our program is the ability to interpret conditional structures. In this scenario
a "second scope" is utilized, as to maintain an awareness of the variables used within that structure. 
That way it can perceive errors outside the structure, if, for example, a variable might be initialized
inside, and used in the function's main block of code. 

-- INTERMEDIATE REPRESENTATIONS (IRs) --

No intermediate representations were utilized.

-- CODE GENERATION -- (when applicable, describe how the code generation of your tool works and identify the possible problems your tool has regarding code generation.)

We generate jasmin code by going through the AST and generating code according to the action being made.
Depending on the type of node, specific code is generated according to it. There is a loopCount and stack
specific for each function of the module, so that we can keep variables in different stack positions, without creating
conflicts. 
All the code responsible for the generation of code is in Generator.java, and the code responsible for writing
the instructions of the file ".j" is in Sampler.java.

-- OVERVIEW -- (refer the approach used in your tool, the main algorithms, the third-party tools and/or packages, etc.)

The main algorithm regarding the Semantic Analysis is done in the file SymbolTable.java, where all the semantic checks were done.
Each function and structure that is evaluated is documented, and it is done simply through the check of the AST generated by the 
parser. There are two main passes, one to simply discover the functions, and the second to analyse what is inside those functions. 
This is done to allow the analysis of calls to functions present later in the code. If a simple linear pass was done, there would be 
no way to know which functions were declared later.

The conditional structures and calls are analysed separately, and operations may be recursively analysed, to garantee that lines 
such as "a = 1 + b +c;" can be properly interpreted.

After a successful semantic analysis, the code generation begins. It starts by going through the AST and,
for specific nodes, it creates the specific code. The ".limit locals" is extracted from the symbol table 
and the ".limit stack" is extracted duting the generation. After each function, all the code generated is 
is in a string called "function", which will be written on the ".j" file after the specification of the ".limit stack".


No external tools or packages were used. 

-- TESTSUITE AND TEST INFRASTRUCTURE -- (Describe the content of your testsuite regarding the number of examples, the approach to automate the test, etc.)

There are no automated tests present in this project.
We tested our project using the the examples given to us by the professors and, after generating the code,
we used the jasmin compiler to verify if our code was correct.

-- INDIVIDUAL SELF-EVALUATION --

Ana Margaria Silva
    - 

Luís Correia
    -

Pedro Reis
    -

Vicente Espinha
    -

-- TASK DISTRIBUTION -- (Identify the set of tasks done by each member of the project.)

The tasks were evenly distributed between the four elements. 

Parser Development - Luís Correia and Pedro Reis
Error Detection - Ana Margarida and Vicente Espinha
Semantic Analysis - Luís Correia and Pedro Reis
Code Generation - Ana Margarida and Vicente Espinha

-- PROS -- (Identify the most positive aspects of your tool)
 
We have a fairly robust error detection and output of warnings. It can handle multiple errors in the same function,
and output specific messages to inform the user of where and why the error has occured.
It can handle mutliple recursive operations embedded in the same line of code, while still checking for semantic errors.

-- CONS --(Identify the most negative aspects of your tool)

Some of the code could be refactored, especially in the SymbolTable and Generator classes. Many bugs that were found during development lied
in that part of the software, and it was usually related to minor tweaks in other areas. 

The code generation for array operations of the example bellow don't work, even though the code generation is
being made with the specific situation in mind (see program2.yal in the testsuite folder).
    Situation:
        a = [N];
        a = 1; // assign the constant to every element of the array


-- GLOBAL PROJECT FINAL GRADE --

Due to the fact taht we didn't implement any optimizations, our maximum grade for this project is 18.
